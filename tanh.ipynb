{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train = pd.read_csv('optdigits.tra', header=None)\n",
    "test = pd.read_csv('optdigits.tes', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort x and y\n",
    "train_x = train.iloc[:, 0:64]\n",
    "train_y = train[64]\n",
    "test_x = test.iloc[:, 0:64]\n",
    "test_y = test[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "train_x = train_x.astype('float32') / 16.\n",
    "test_x = test_x.astype('float32') / 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training set and validation set\n",
    "new_train_x, val_x, new_train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed dataset into numpy\n",
    "new_train_x = new_train_x.to_numpy()\n",
    "new_train_y = new_train_y.to_numpy()\n",
    "val_x = val_x.to_numpy()\n",
    "val_y = val_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape of y data set\n",
    "new_train_y = to_categorical(new_train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "val_y = to_categorical(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, activation='tanh'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SGD as the optimizer\n",
    "opt = SGD(learning_rate=0.2, momentum=0.2, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, patience=0, \n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiling\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/180\n",
      "3058/3058 [==============================] - 1s 277us/sample - loss: 0.6018 - accuracy: 0.8623 - val_loss: 0.2258 - val_accuracy: 0.9503\n",
      "Epoch 2/180\n",
      "3058/3058 [==============================] - 0s 139us/sample - loss: 0.1856 - accuracy: 0.9545 - val_loss: 0.1653 - val_accuracy: 0.9634\n",
      "Epoch 3/180\n",
      "3058/3058 [==============================] - 0s 136us/sample - loss: 0.1360 - accuracy: 0.9630 - val_loss: 0.1387 - val_accuracy: 0.9608\n",
      "Epoch 4/180\n",
      "3058/3058 [==============================] - 0s 147us/sample - loss: 0.1126 - accuracy: 0.9696 - val_loss: 0.1335 - val_accuracy: 0.9621\n",
      "Epoch 5/180\n",
      "3058/3058 [==============================] - 0s 134us/sample - loss: 0.0957 - accuracy: 0.9755 - val_loss: 0.1222 - val_accuracy: 0.9621\n",
      "Epoch 6/180\n",
      "3058/3058 [==============================] - 0s 149us/sample - loss: 0.0863 - accuracy: 0.9801 - val_loss: 0.1176 - val_accuracy: 0.9621\n",
      "Epoch 7/180\n",
      "3058/3058 [==============================] - 0s 137us/sample - loss: 0.0800 - accuracy: 0.9784 - val_loss: 0.1084 - val_accuracy: 0.9686\n",
      "Epoch 8/180\n",
      "3058/3058 [==============================] - 0s 146us/sample - loss: 0.0716 - accuracy: 0.9814 - val_loss: 0.1102 - val_accuracy: 0.9699\n",
      "3.9968209266662598\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "start = time()\n",
    "model.fit(new_train_x, new_train_y, epochs= 180, batch_size=15,\n",
    "          callbacks = [early_stop], validation_data=(val_x, val_y))\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of training set  >>> counted with for loops\n",
    "dist_train = [376,389,380,389,387,376,377,387,380,382]\n",
    "# Distribution of testing set\n",
    "dist_test = [178,182,177,183,181,182,181,179,174,180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracay of overall classification accuracy and class accuracy\n",
    "def accuracy_overall(pred, actual, num_classes):\n",
    "    result = int()\n",
    "# Overall classfication accuracy\n",
    "    overall = np.where(pred == actual)[0]\n",
    "    overall_acc = float(len(overall))/len(pred)\n",
    "    result = overall_acc\n",
    "    return result\n",
    "\n",
    "def accuracy(pred, actual, num_classes):\n",
    "# Class accuracy\n",
    "    result = []\n",
    "    classes = np.array([float(0)]*10)\n",
    "    for i in range(0,len(pred)):\n",
    "        id_classes = int(actual[i])\n",
    "        if pred[i] == actual[i]:\n",
    "            classes[id_classes] = classes[id_classes] + 1\n",
    "    classes_acc = classes/num_classes\n",
    "    result.append(classes_acc)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def confusion_matrix(pred, actual):\n",
    "    matrix = np.array([int(0)]*10*10).reshape(10,10)\n",
    "    for i in range(0,10):\n",
    "        pred_i = pred[np.where(np.array(actual) == i)]\n",
    "        conf = []\n",
    "        for j in range(0,10):\n",
    "            length = len(np.where(pred_i == j)[0])\n",
    "            conf.append(length)\n",
    "        matrix[i,] = conf\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[64]\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(train_x)\n",
    "predict_train_class = predict_train.argmax(axis=-1)\n",
    "acc_train_overall = accuracy_overall(predict_train_class, train_y, dist_train)\n",
    "acc_train_class = accuracy(predict_train_class, train_y, dist_train)\n",
    "conf_train = confusion_matrix(predict_train_class, train_y)\n",
    "\n",
    "\n",
    "predict_test = model.predict(test_x)\n",
    "predict_test_class = predict_test.argmax(axis=-1)\n",
    "acc_test_overall = accuracy_overall(predict_test_class, test_y, dist_test)\n",
    "acc_test_class = accuracy(predict_test_class, test_y, dist_test)\n",
    "conf_test = confusion_matrix(predict_test_class, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set overall accuracy\n",
      "\n",
      "0.9814281977504578\n",
      "\n",
      "\n",
      "training set class accuracy\n",
      "\n",
      "[array([0.99468085, 0.98971722, 0.99473684, 0.97686375, 0.95607235,\n",
      "       0.9787234 , 0.99204244, 0.98449612, 0.98157895, 0.96596859])]\n",
      "\n",
      "\n",
      "training set confusion matrix\n",
      "\n",
      "[[374   0   0   0   0   0   1   0   1   0]\n",
      " [  0 385   0   0   0   0   0   1   1   2]\n",
      " [  1   0 378   0   0   0   0   0   1   0]\n",
      " [  0   1   0 380   0   3   0   0   1   4]\n",
      " [  1   2   0   0 370   0   3   0   3   8]\n",
      " [  0   1   2   1   0 368   1   0   0   3]\n",
      " [  0   2   0   0   1   0 374   0   0   0]\n",
      " [  0   0   2   2   0   0   0 381   0   2]\n",
      " [  0   5   0   0   1   0   1   0 373   0]\n",
      " [  1   4   0   2   2   1   0   0   3 369]]\n",
      "\n",
      "\n",
      "testing set overall accuracy\n",
      "\n",
      "0.9532554257095158\n",
      "\n",
      "\n",
      "testing set class accuracy\n",
      "\n",
      "[array([0.98876404, 0.98901099, 0.96045198, 0.92896175, 0.96685083,\n",
      "       0.96703297, 0.98342541, 0.87150838, 0.91954023, 0.95555556])]\n",
      "\n",
      "\n",
      "testing set confusion matrix\n",
      "\n",
      "[[176   0   1   0   0   1   0   0   0   0]\n",
      " [  0 180   0   0   0   0   0   0   0   2]\n",
      " [  0   6 170   0   0   0   1   0   0   0]\n",
      " [  0   0   5 170   0   3   0   0   3   2]\n",
      " [  0   2   0   0 175   0   1   0   3   0]\n",
      " [  0   1   1   0   0 176   1   0   0   3]\n",
      " [  2   1   0   0   0   0 178   0   0   0]\n",
      " [  0   0   0   0   1   7   0 156   4  11]\n",
      " [  0   8   0   0   0   2   0   0 160   4]\n",
      " [  0   3   0   1   0   2   0   0   2 172]]\n"
     ]
    }
   ],
   "source": [
    "#output results\n",
    "print(\"training set overall accuracy\" + \"\\n\")\n",
    "print(acc_train_overall)\n",
    "print(\"\\n\")\n",
    "print(\"training set class accuracy\" + \"\\n\")\n",
    "print(acc_train_class)\n",
    "print(\"\\n\")\n",
    "print(\"training set confusion matrix\" + \"\\n\")\n",
    "print(conf_train)\n",
    "print(\"\\n\")\n",
    "print(\"testing set overall accuracy\" + \"\\n\")\n",
    "print(acc_test_overall)\n",
    "print(\"\\n\")\n",
    "print(\"testing set class accuracy\" + \"\\n\")\n",
    "print(acc_test_class)\n",
    "print(\"\\n\")\n",
    "print(\"testing set confusion matrix\" + \"\\n\")\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
