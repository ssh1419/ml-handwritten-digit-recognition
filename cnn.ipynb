{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from time import time\n",
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train = pd.read_csv('optdigits.tra', header=None)\n",
    "test = pd.read_csv('optdigits.tes', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort x and y\n",
    "train_x = train.iloc[:, 0:64]\n",
    "train_y = train[64]\n",
    "test_x = test.iloc[:, 0:64]\n",
    "test_y = test[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "train_x = train_x.astype('float32') / 16.\n",
    "test_x = test_x.astype('float32') / 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training set and validation set\n",
    "new_train_x, val_x, new_train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed dataset into numpy\n",
    "new_train_x = new_train_x.to_numpy()\n",
    "new_train_y = new_train_y.to_numpy()\n",
    "val_x = val_x.to_numpy()\n",
    "val_y = val_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape of y data set\n",
    "conv_train_x = new_train_x.reshape(new_train_x.shape[0],8,8,1)\n",
    "conv_test_x = test_x.reshape(test_x.shape[0],8,8,1)\n",
    "conv_val_x = val_x.reshape(val_x.shape[0],8,8,1)\n",
    "conv_train_y = to_categorical(new_train_y)\n",
    "conv_test_y = to_categorical(test_y)\n",
    "conv_val_y = to_categorical(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=(5,5), activation= 'relu', input_shape=(8,8,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation= 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SGD as the optimizer\n",
    "opt = SGD(learning_rate=0.2, momentum=0.2, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, patience=0, \n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiling\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/150\n",
      "3058/3058 [==============================] - 0s 153us/step - loss: 0.5117 - accuracy: 0.8473 - val_loss: 0.2791 - val_accuracy: 0.9216\n",
      "Epoch 2/150\n",
      "3058/3058 [==============================] - 0s 132us/step - loss: 0.1612 - accuracy: 0.9493 - val_loss: 0.2046 - val_accuracy: 0.9438\n",
      "Epoch 3/150\n",
      "3058/3058 [==============================] - 0s 137us/step - loss: 0.1259 - accuracy: 0.9595 - val_loss: 0.1375 - val_accuracy: 0.9556\n",
      "Epoch 4/150\n",
      "3058/3058 [==============================] - 0s 146us/step - loss: 0.0995 - accuracy: 0.9709 - val_loss: 0.1168 - val_accuracy: 0.9673\n",
      "Epoch 5/150\n",
      "3058/3058 [==============================] - 0s 129us/step - loss: 0.0828 - accuracy: 0.9725 - val_loss: 0.1201 - val_accuracy: 0.9660\n",
      "2.481171131134033\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "start = time()\n",
    "model.fit(conv_train_x, conv_train_y, epochs= 150, batch_size=15,\n",
    "          callbacks = [early_stop], validation_data=(conv_val_x, conv_val_y))\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of training set  >>> counted with for loops\n",
    "dist_train = [376,389,380,389,387,376,377,387,380,382]\n",
    "# Distribution of testing set\n",
    "dist_test = [178,182,177,183,181,182,181,179,174,180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracay of overall classification accuracy and class accuracy\n",
    "def accuracy_overall(pred, actual, num_classes):\n",
    "    result = int()\n",
    "# Overall classfication accuracy\n",
    "    overall = np.where(pred == actual)[0]\n",
    "    overall_acc = float(len(overall))/len(pred)\n",
    "    result = overall_acc\n",
    "    return result\n",
    "\n",
    "def accuracy(pred, actual, num_classes):\n",
    "# Class accuracy\n",
    "    result = []\n",
    "    classes = np.array([float(0)]*10)\n",
    "    for i in range(0,len(pred)):\n",
    "        id_classes = int(actual[i])\n",
    "        if pred[i] == actual[i]:\n",
    "            classes[id_classes] = classes[id_classes] + 1\n",
    "    classes_acc = classes/num_classes\n",
    "    result.append(classes_acc)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def confusion_matrix(pred, actual):\n",
    "    matrix = np.array([int(0)]*10*10).reshape(10,10)\n",
    "    for i in range(0,10):\n",
    "        pred_i = pred[np.where(np.array(actual) == i)]\n",
    "        conf = []\n",
    "        for j in range(0,10):\n",
    "            length = len(np.where(pred_i == j)[0])\n",
    "            conf.append(length)\n",
    "        matrix[i,] = conf\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[64]\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "train_x = train_x.reshape(train_x.shape[0],8,8,1)\n",
    "test_x = test_x.reshape(test_x.shape[0],8,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(train_x)\n",
    "predict_train_class = predict_train.argmax(axis=-1)\n",
    "acc_train_overall = accuracy_overall(predict_train_class, train_y, dist_train)\n",
    "acc_train_class = accuracy(predict_train_class, train_y, dist_train)\n",
    "conf_train = confusion_matrix(predict_train_class, train_y)\n",
    "\n",
    "\n",
    "predict_test = model.predict(test_x)\n",
    "predict_test_class = predict_test.argmax(axis=-1)\n",
    "acc_test_overall = accuracy_overall(predict_test_class, test_y, dist_test)\n",
    "acc_test_class = accuracy(predict_test_class, test_y, dist_test)\n",
    "conf_test = confusion_matrix(predict_test_class, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set overall accuracy\n",
      "\n",
      "0.9816897724300288\n",
      "\n",
      "\n",
      "training set class accuracy\n",
      "\n",
      "[array([0.99468085, 0.98457584, 0.98947368, 0.96143959, 0.97674419,\n",
      "       0.98138298, 0.99204244, 0.99741602, 0.98421053, 0.95549738])]\n",
      "\n",
      "\n",
      "training set confusion matrix\n",
      "\n",
      "[[374   0   0   0   1   0   0   0   1   0]\n",
      " [  0 383   0   0   0   0   0   1   3   2]\n",
      " [  0   1 376   0   0   0   0   1   1   1]\n",
      " [  0   0   1 374   0   4   0   1   5   4]\n",
      " [  0   0   0   0 378   0   2   0   0   7]\n",
      " [  0   1   2   1   0 369   0   0   0   3]\n",
      " [  0   2   0   0   1   0 374   0   0   0]\n",
      " [  0   0   0   1   0   0   0 386   0   0]\n",
      " [  0   3   0   0   1   0   1   0 374   1]\n",
      " [  0   5   2   2   2   1   0   1   4 365]]\n",
      "\n",
      "\n",
      "testing set overall accuracy\n",
      "\n",
      "0.9571508069003896\n",
      "\n",
      "\n",
      "testing set class accuracy\n",
      "\n",
      "[array([0.99438202, 0.96703297, 0.97740113, 0.92349727, 0.95027624,\n",
      "       0.97802198, 0.97790055, 0.92178771, 0.93103448, 0.95      ])]\n",
      "\n",
      "\n",
      "testing set confusion matrix\n",
      "\n",
      "[[177   0   0   0   1   0   0   0   0   0]\n",
      " [  0 176   0   0   0   0   1   0   2   3]\n",
      " [  0   2 173   0   0   0   0   1   1   0]\n",
      " [  0   0   0 169   0   3   0   3   7   1]\n",
      " [  0   5   0   0 172   0   0   1   3   0]\n",
      " [  0   0   0   0   0 178   2   0   0   2]\n",
      " [  0   1   0   0   2   0 177   0   1   0]\n",
      " [  0   0   0   0   0   4   0 165   2   8]\n",
      " [  0   7   0   0   0   2   0   1 162   2]\n",
      " [  0   0   0   0   4   2   0   0   3 171]]\n"
     ]
    }
   ],
   "source": [
    "#output results\n",
    "print(\"training set overall accuracy\" + \"\\n\")\n",
    "print(acc_train_overall)\n",
    "print(\"\\n\")\n",
    "print(\"training set class accuracy\" + \"\\n\")\n",
    "print(acc_train_class)\n",
    "print(\"\\n\")\n",
    "print(\"training set confusion matrix\" + \"\\n\")\n",
    "print(conf_train)\n",
    "print(\"\\n\")\n",
    "print(\"testing set overall accuracy\" + \"\\n\")\n",
    "print(acc_test_overall)\n",
    "print(\"\\n\")\n",
    "print(\"testing set class accuracy\" + \"\\n\")\n",
    "print(acc_test_class)\n",
    "print(\"\\n\")\n",
    "print(\"testing set confusion matrix\" + \"\\n\")\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
