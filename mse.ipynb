{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train = pd.read_csv('optdigits.tra', header=None)\n",
    "test = pd.read_csv('optdigits.tes', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort x and y\n",
    "train_x = train.iloc[:, 0:64]\n",
    "train_y = train[64]\n",
    "test_x = test.iloc[:, 0:64]\n",
    "test_y = test[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "train_x = train_x.astype('float32') / 16.\n",
    "test_x = test_x.astype('float32') / 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training set and validation set\n",
    "new_train_x, val_x, new_train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed dataset into numpy\n",
    "new_train_x = new_train_x.to_numpy()\n",
    "new_train_y = new_train_y.to_numpy()\n",
    "val_x = val_x.to_numpy()\n",
    "val_y = val_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape of y data set\n",
    "new_train_y = to_categorical(new_train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "val_y = to_categorical(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(30, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SGD as the optimizer\n",
    "opt = SGD(learning_rate=0.3, momentum=0.3, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, patience=0, \n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiling\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3058 samples, validate on 765 samples\n",
      "Epoch 1/180\n",
      "3058/3058 [==============================] - 1s 283us/sample - loss: 0.0844 - accuracy: 0.3450 - val_loss: 0.0771 - val_accuracy: 0.5373\n",
      "Epoch 2/180\n",
      "3058/3058 [==============================] - 0s 151us/sample - loss: 0.0661 - accuracy: 0.6024 - val_loss: 0.0551 - val_accuracy: 0.6706\n",
      "Epoch 3/180\n",
      "3058/3058 [==============================] - 0s 149us/sample - loss: 0.0452 - accuracy: 0.7665 - val_loss: 0.0354 - val_accuracy: 0.8706\n",
      "Epoch 4/180\n",
      "3058/3058 [==============================] - 0s 152us/sample - loss: 0.0279 - accuracy: 0.9065 - val_loss: 0.0215 - val_accuracy: 0.9307\n",
      "Epoch 5/180\n",
      "3058/3058 [==============================] - 0s 141us/sample - loss: 0.0185 - accuracy: 0.9287 - val_loss: 0.0150 - val_accuracy: 0.9412\n",
      "Epoch 6/180\n",
      "3058/3058 [==============================] - 0s 154us/sample - loss: 0.0143 - accuracy: 0.9359 - val_loss: 0.0126 - val_accuracy: 0.9542\n",
      "Epoch 7/180\n",
      "3058/3058 [==============================] - 0s 145us/sample - loss: 0.0121 - accuracy: 0.9411 - val_loss: 0.0107 - val_accuracy: 0.9542\n",
      "Epoch 8/180\n",
      "3058/3058 [==============================] - 0s 159us/sample - loss: 0.0106 - accuracy: 0.9496 - val_loss: 0.0098 - val_accuracy: 0.9529\n",
      "Epoch 9/180\n",
      "3058/3058 [==============================] - 0s 137us/sample - loss: 0.0097 - accuracy: 0.9519 - val_loss: 0.0092 - val_accuracy: 0.9503\n",
      "Epoch 10/180\n",
      "3058/3058 [==============================] - 1s 229us/sample - loss: 0.0089 - accuracy: 0.9562 - val_loss: 0.0085 - val_accuracy: 0.9542\n",
      "Epoch 11/180\n",
      "3058/3058 [==============================] - 1s 168us/sample - loss: 0.0083 - accuracy: 0.9608 - val_loss: 0.0084 - val_accuracy: 0.9503\n",
      "Epoch 12/180\n",
      "3058/3058 [==============================] - 1s 204us/sample - loss: 0.0079 - accuracy: 0.9585 - val_loss: 0.0077 - val_accuracy: 0.9556\n",
      "Epoch 13/180\n",
      "3058/3058 [==============================] - 0s 150us/sample - loss: 0.0075 - accuracy: 0.9624 - val_loss: 0.0076 - val_accuracy: 0.9556\n",
      "Epoch 14/180\n",
      "3058/3058 [==============================] - 0s 152us/sample - loss: 0.0071 - accuracy: 0.9640 - val_loss: 0.0076 - val_accuracy: 0.9569\n",
      "Epoch 15/180\n",
      "3058/3058 [==============================] - 0s 153us/sample - loss: 0.0068 - accuracy: 0.9653 - val_loss: 0.0071 - val_accuracy: 0.9595\n",
      "Epoch 16/180\n",
      "3058/3058 [==============================] - 1s 203us/sample - loss: 0.0065 - accuracy: 0.9666 - val_loss: 0.0069 - val_accuracy: 0.9569\n",
      "Epoch 17/180\n",
      "3058/3058 [==============================] - 1s 198us/sample - loss: 0.0063 - accuracy: 0.9686 - val_loss: 0.0068 - val_accuracy: 0.9621\n",
      "Epoch 18/180\n",
      "3058/3058 [==============================] - 0s 163us/sample - loss: 0.0061 - accuracy: 0.9709 - val_loss: 0.0069 - val_accuracy: 0.9595\n",
      "9.625683069229126\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "start = time()\n",
    "model.fit(new_train_x, new_train_y, epochs=180, batch_size=15,\n",
    "          callbacks = [early_stop], validation_data=(val_x, val_y))\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of training set  >>> counted with for loops\n",
    "dist_train = [376,389,380,389,387,376,377,387,380,382]\n",
    "# Distribution of testing set\n",
    "dist_test = [178,182,177,183,181,182,181,179,174,180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracay of overall classification accuracy and class accuracy\n",
    "def accuracy_overall(pred, actual, num_classes):\n",
    "    result = int()\n",
    "# Overall classfication accuracy\n",
    "    overall = np.where(pred == actual)[0]\n",
    "    overall_acc = float(len(overall))/len(pred)\n",
    "    result = overall_acc\n",
    "    return result\n",
    "\n",
    "def accuracy(pred, actual, num_classes):\n",
    "# Class accuracy\n",
    "    result = []\n",
    "    classes = np.array([float(0)]*10)\n",
    "    for i in range(0,len(pred)):\n",
    "        id_classes = int(actual[i])\n",
    "        if pred[i] == actual[i]:\n",
    "            classes[id_classes] = classes[id_classes] + 1\n",
    "    classes_acc = classes/num_classes\n",
    "    result.append(classes_acc)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def confusion_matrix(pred, actual):\n",
    "    matrix = np.array([int(0)]*10*10).reshape(10,10)\n",
    "    for i in range(0,10):\n",
    "        pred_i = pred[np.where(np.array(actual) == i)]\n",
    "        conf = []\n",
    "        for j in range(0,10):\n",
    "            length = len(np.where(pred_i == j)[0])\n",
    "            conf.append(length)\n",
    "        matrix[i,] = conf\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[64]\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(train_x)\n",
    "predict_train_class = predict_train.argmax(axis=-1)\n",
    "acc_train_overall = accuracy_overall(predict_train_class, train_y, dist_train)\n",
    "acc_train_class = accuracy(predict_train_class, train_y, dist_train)\n",
    "conf_train = confusion_matrix(predict_train_class, train_y)\n",
    "\n",
    "\n",
    "predict_test = model.predict(test_x)\n",
    "predict_test_class = predict_test.argmax(axis=-1)\n",
    "acc_test_overall = accuracy_overall(predict_test_class, test_y, dist_test)\n",
    "acc_test_class = accuracy(predict_test_class, test_y, dist_test)\n",
    "conf_test = confusion_matrix(predict_test_class, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set overall accuracy\n",
      "\n",
      "0.9707036358880461\n",
      "\n",
      "\n",
      "training set class accuracy\n",
      "\n",
      "[array([0.99202128, 0.95372751, 0.98421053, 0.96915167, 0.9379845 ,\n",
      "       0.98138298, 0.9867374 , 0.98966408, 0.96842105, 0.94502618])]\n",
      "\n",
      "\n",
      "training set confusion matrix\n",
      "\n",
      "[[373   0   0   0   1   0   1   0   1   0]\n",
      " [  0 371   3   0   1   1   0   3   6   4]\n",
      " [  0   0 374   0   0   0   1   2   2   1]\n",
      " [  0   0   1 377   0   6   0   0   1   4]\n",
      " [  1   2   0   0 363   0   4   0   6  11]\n",
      " [  0   1   2   1   0 369   0   0   0   3]\n",
      " [  1   3   0   0   1   0 372   0   0   0]\n",
      " [  0   0   1   1   1   0   0 383   0   1]\n",
      " [  0   4   0   2   3   2   1   0 368   0]\n",
      " [  1   4   1   3   4   1   0   3   4 361]]\n",
      "\n",
      "\n",
      "testing set overall accuracy\n",
      "\n",
      "0.9465776293823038\n",
      "\n",
      "\n",
      "testing set class accuracy\n",
      "\n",
      "[array([0.97191011, 0.93956044, 0.97175141, 0.91256831, 0.97790055,\n",
      "       0.98351648, 0.96132597, 0.92178771, 0.8908046 , 0.93333333])]\n",
      "\n",
      "\n",
      "testing set confusion matrix\n",
      "\n",
      "[[173   0   0   0   1   4   0   0   0   0]\n",
      " [  0 171   2   0   0   1   0   0   1   7]\n",
      " [  0   3 172   0   0   0   0   2   0   0]\n",
      " [  0   0   6 167   0   4   0   2   2   2]\n",
      " [  0   0   0   0 177   0   0   0   3   1]\n",
      " [  0   1   0   0   0 179   0   0   0   2]\n",
      " [  1   4   0   0   1   0 174   0   1   0]\n",
      " [  0   0   0   0   1   6   0 165   2   5]\n",
      " [  0   9   0   0   0   5   0   0 155   5]\n",
      " [  0   1   1   1   5   2   0   0   2 168]]\n"
     ]
    }
   ],
   "source": [
    "#output results\n",
    "print(\"training set overall accuracy\" + \"\\n\")\n",
    "print(acc_train_overall)\n",
    "print(\"\\n\")\n",
    "print(\"training set class accuracy\" + \"\\n\")\n",
    "print(acc_train_class)\n",
    "print(\"\\n\")\n",
    "print(\"training set confusion matrix\" + \"\\n\")\n",
    "print(conf_train)\n",
    "print(\"\\n\")\n",
    "print(\"testing set overall accuracy\" + \"\\n\")\n",
    "print(acc_test_overall)\n",
    "print(\"\\n\")\n",
    "print(\"testing set class accuracy\" + \"\\n\")\n",
    "print(acc_test_class)\n",
    "print(\"\\n\")\n",
    "print(\"testing set confusion matrix\" + \"\\n\")\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
